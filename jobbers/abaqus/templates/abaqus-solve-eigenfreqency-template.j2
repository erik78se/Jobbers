#!/bin/python3
## Generic information
# Job name
#SBATCH -J {{job.jobname}}
# Job time limit in minutes
#SBATCH -t {{job.timelimit}}
# TODO: Name of account (not user) for accounting.
#SBATCH -A abaqus
# TODO: VERIFY! an email is send at the start and end
#SBATCH --mail-type=ALL
# which partitions to consider
#SBATCH --partition {{job.partitions|join(",")}}
##  Jobpack 1
# Nodes to use - always one master node
#SBATCH -N 1
{% if job.masternode_mem %}
# Memory requirement on master node
#SBATCH --mem={{job.masternode_mem}}
{% endif %}
# Licenses required, appointed to master job
#SBATCH --lic {{job.abaqus_licenses.license}}:{{job.abaqus_licenses.volume}}
# Exclusive execution on head node
#SBATCH --exclusive

# Import required python modules
import os
import sys
import subprocess
import glob
import shutil
import pwd
import json
from pathlib import Path

# Project is the name of the script and template
PROJECT = "abaqus-solve-eigenfreqency"

# Get job information from SLURM
JOB_NAME = os.getenv('SLURM_JOB_NAME')
HOSTNAME = os.getenv('HOSTNAME')
USER = os.getenv('USER')
JOB_ID = os.getenv('SLURM_JOBID')
STARTDIR = os.getenv('SLURM_SUBMIT_DIR')

# Unset variable to avoid strange bug
if "SLURM_GTIDS" in os.environ:
    del os.environ['SLURM_GTIDS']


# Get compute hosts and total number of CPUs
LSB_MCPU_HOSTS = ''
cpus = 0
HOST_SPLIT = 1
if 'SLURM_PACK_SIZE' in os.environ:
    sys.exit(f' ERROR: Abaqus Eigenfreqency jobs may not be distributed on several nodes, exiting!')
else:
    for host in os.getenv('SLURM_JOB_NODELIST').split(','):
        LSB_MCPU_HOSTS += "%s %s " % (host, os.getenv('SLURM_CPUS_ON_NODE'))
        cpus += int(os.getenv('SLURM_CPUS_ON_NODE'))

try:
    # Create scratch folder
    local_scratch_folder = f'/scratch/{USER}/abaqus_job_{JOB_ID}'
    try:
        os.makedirs(local_scratch_folder)
    except OSError:
        sys.exit(f'ERROR: Local scratch folder could not be created:\n\t{local_scratch_folder}')

    linksrc = f'/net/{HOSTNAME}{local_scratch_folder}'
    scratchlink = Path(f'{JOB_NAME}_{JOB_ID}')
    scratchlink.symlink_to(linksrc)

    # Stage required files to local scratch
    files_to_stage_up = {{job.inpfile.files_to_stage()}}
    try:
        for stage_up_file in files_to_stage_up:
            for source_file in glob.glob("%s" % stage_up_file):
                target_file = os.path.join(local_scratch_folder, os.path.basename(source_file))
                shutil.copy(source_file, target_file)
    except (IOError, os.error) as why:
        sys.exit(f' ERROR: Stage up failed: \n\t Source: {source_file} \n\t Target: {target_file} \n\t Problem: {str(why)}')

    # Load application module into local env
    module_env = dict()
    module_abq = '{{job.abaqus_module.module}}'
    module_cmd = f'module load {module_abq}'
    dump_cmd = '/usr/bin/python -c "import os, json;print json.dumps(dict(os.environ))"'
    module_process = subprocess.Popen(['/bin/bash', '-c', f'{module_cmd} && {dump_cmd}'], stdout=subprocess.PIPE)
    (module_out, module_err) = module_process.communicate()
    module_process_exit_status = module_process.wait(10)
    if module_process_exit_status != 0:
        sys.exit(f'ERROR: Abaqus module {module_abq} could not be loaded, exiting.\n\tModule:{module_abq}\n\tstdout: {module_out}\n\tstderr: {module_err}')
    else:
        module_env = json.loads(module_out)

    # Assemble command line
    abaqus_cmd = ['ABQLauncher',
                  f'job={JOB_NAME}',
                  f'input={os.path.basename("{{job.inpfile.file}}")}',
                  'interactive',
{% if job.restartjobname %}
                  f'oldjob={{job.restartjobname}}',
{% endif %}
                  f'cpus={str(cpus)}',
                  f'mp_host_split={str(HOST_SPLIT)}']

    module_env['LSB_MCPU_HOSTS'] = LSB_MCPU_HOSTS
    module_env['MPI_REMSH'] = 'ssh -x -q -o StrictHostKeyChecking=no'

    print("==== BEGIN ENVIRONMENT DUMP ====")
    for param in os.environ.keys():
        print(f'{param}: {os.environ[param]}')
    print("==== END ENVIRONMENT DUMP ====")

    # Launch application
    # TODO: Encapsulate process in processManager
    print(*abaqus_cmd, sep=" ")
    abaqus_process = subprocess.Popen(abaqus_cmd, shell=False, cwd=local_scratch_folder, env=module_env, stdout=subprocess.PIPE)
    (abaqus_out, abaqus_err) = abaqus_process.communicate()
    abaqus_exit_status = abaqus_process.wait()

    if abaqus_exit_status == 0:
        print("Abaqus was run successfully")
        exit_status = "Done"
    else:
        print(f'Abaqus exited with ERROR CODE {str(abaqus_exit_status)}\nstdout: {abaqus_out}\nstderr: {abaqus_err}')
        exit_status = "Exited"

    # Stage back result files files to local scratch
    files_to_stage_back = [
    ]
    files_to_stage_back = glob.glob(f'{os.path.join(local_scratch_folder,JOB_NAME + ".*")}')
    try:
        print(f'Staging back:')
        for stage_back_file in files_to_stage_back:
            print(f'\t - {stage_back_file}')
            target_file = os.path.join(STARTDIR, os.path.basename(stage_back_file))
            shutil.copy(stage_back_file, target_file)
            # TODO: Check what this line actually does
            # os.chown(target_file, pwd.getpwnam(USER).pw_uid, 2410)
    except (IOError, os.error) as why:
        sys.exit(f' ERROR: Stage back failed: \n\t Source: {source_file} \n\t Target: {target_file} \n\t Problem: {str(why)}')

finally:
    # CLEANING
    print(f'Removing files in directory /scratch/{USER} at cluster node {HOSTNAME}')
    try:
        if os.path.exists(local_scratch_folder):
            shutil.rmtree(local_scratch_folder)
        # Remove the scratchlink
        if os.path.islink(scratchlink):
            scratchlink.unlink()
    except (IOError, os.error) as why:
        sys.exit(f' ERROR: Cleanup failed on compute host, remove files manually:\n\t Problem: {str(why)}')

